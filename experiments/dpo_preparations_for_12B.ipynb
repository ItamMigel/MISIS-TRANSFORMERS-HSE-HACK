{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZV6wpfnlHfJ6"
   },
   "outputs": [],
   "source": [
    "!pip install trl datasets bitsandbytes accelerate peft tensorboardX -qqU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEHAVt9fGyIM"
   },
   "source": [
    "## DPO Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IPopRRZIHmRa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_XezZgj7KGuo"
   },
   "outputs": [],
   "source": [
    "path = '/home/jovyan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A1IRTud09TPR"
   },
   "outputs": [],
   "source": [
    "preferences_df = pd.read_csv(path + 'dpo_chosen_rejected_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lA5kzK6r9TR3"
   },
   "outputs": [],
   "source": [
    "## на завтра\n",
    "## убрать из промпта тесты\n",
    "## проверить эту гипотезу\n",
    "## + проверить, оставив только решения и условие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xWqe7A0j9TUU",
    "outputId": "9992319a-ddec-4ff5-cc56-6dbb69daa758"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>description</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>student_solution</th>\n",
       "      <th>author_solution</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>conversations</th>\n",
       "      <th>conversations2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>Напишите функцию, определяющую дизайнера, кото...</td>\n",
       "      <td>[\"['Круглов', 'Квадратов', 'Иванов', 'Марков',...</td>\n",
       "      <td>['Гуськов', 'Краков', 'Волков', 'Стариков', 'П...</td>\n",
       "      <td>def designer (designers, sizes, towns):\\n    l...</td>\n",
       "      <td>def designer (designers, sizes, towns):\\n    s...</td>\n",
       "      <td>Ошибка при использовании функции min(). Функци...</td>\n",
       "      <td>['open', 'open', 'closed', 'closed', 'closed',...</td>\n",
       "      <td>&lt;Task description&gt;: Напишите функцию, определя...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>Реализуйте программу, которая определит количе...</td>\n",
       "      <td>['ПРОЕКТ 1\\nПРОЕКТ_2\\nпроект 3\\nПроект_4\\nинте...</td>\n",
       "      <td>['1', '0', '1', '1', '1']</td>\n",
       "      <td>result = 0\\n\\nwhile True:\\n    info = input()\\...</td>\n",
       "      <td>result = 0\\n\\nwhile True:\\n    info = input()\\...</td>\n",
       "      <td>Обратите внимание на ошибку в табуляции выраже...</td>\n",
       "      <td>['open', 'open', 'closed', 'closed', 'closed']</td>\n",
       "      <td>&lt;Task description&gt;: Реализуйте программу, кото...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  id  task_id  \\\n",
       "51            51          51  94        6   \n",
       "15            15          15  28        2   \n",
       "\n",
       "                                          description  \\\n",
       "51  Напишите функцию, определяющую дизайнера, кото...   \n",
       "15  Реализуйте программу, которая определит количе...   \n",
       "\n",
       "                                                input  \\\n",
       "51  [\"['Круглов', 'Квадратов', 'Иванов', 'Марков',...   \n",
       "15  ['ПРОЕКТ 1\\nПРОЕКТ_2\\nпроект 3\\nПроект_4\\nинте...   \n",
       "\n",
       "                                               output  \\\n",
       "51  ['Гуськов', 'Краков', 'Волков', 'Стариков', 'П...   \n",
       "15                          ['1', '0', '1', '1', '1']   \n",
       "\n",
       "                                     student_solution  \\\n",
       "51  def designer (designers, sizes, towns):\\n    l...   \n",
       "15  result = 0\\n\\nwhile True:\\n    info = input()\\...   \n",
       "\n",
       "                                      author_solution  \\\n",
       "51  def designer (designers, sizes, towns):\\n    s...   \n",
       "15  result = 0\\n\\nwhile True:\\n    info = input()\\...   \n",
       "\n",
       "                                       author_comment  \\\n",
       "51  Ошибка при использовании функции min(). Функци...   \n",
       "15  Обратите внимание на ошибку в табуляции выраже...   \n",
       "\n",
       "                                                 type  \\\n",
       "51  ['open', 'open', 'closed', 'closed', 'closed',...   \n",
       "15     ['open', 'open', 'closed', 'closed', 'closed']   \n",
       "\n",
       "                                               prompt  \\\n",
       "51  <Task description>: Напишите функцию, определя...   \n",
       "15  <Task description>: Реализуйте программу, кото...   \n",
       "\n",
       "                                        conversations  \\\n",
       "51  [{'role': 'system', 'content': '\\n\\n###INSTRUC...   \n",
       "15  [{'role': 'system', 'content': '\\n\\n###INSTRUC...   \n",
       "\n",
       "                                       conversations2  \n",
       "51  [{'role': 'system', 'content': '\\n\\n###INSTRUC...  \n",
       "15  [{'role': 'system', 'content': '\\n\\n###INSTRUC...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zerf_xta9TWu",
    "outputId": "4de4a947-1ad1-436b-873b-3a8e9225eddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wM88c2fi9TZY"
   },
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "chosen_list = []\n",
    "rejected_list = []\n",
    "messages_list = [] # = chosen\n",
    "\n",
    "for index, row in preferences_df.iterrows():\n",
    "  prompt = row['prompt']\n",
    "  prompt_list.append(prompt)\n",
    "  chosen = row['conversations']\n",
    "  chosen_list.append(chosen)\n",
    "  messages_list.append(chosen)\n",
    "  rejected = row['conversations2']\n",
    "  rejected_list.append(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rpdAiL2I9TcJ"
   },
   "outputs": [],
   "source": [
    "preferences_dpo_df = pd.DataFrame({'prompt': prompt_list,\n",
    "                                   'chosen': chosen_list,\n",
    "                                   'rejected': rejected_list,\n",
    "                                   'messages': messages_list,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "H0Mrmh7n9Tej",
    "outputId": "1b9d8e04-3761-44a0-baf6-5a5918150d87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>&lt;Task description&gt;: Роман изучает свой отчет п...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>&lt;Task description&gt;: Напишите функцию, определя...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "      <td>[{'role': 'system', 'content': '\\n\\n###INSTRUC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "253  <Task description>: Роман изучает свой отчет п...   \n",
       "96   <Task description>: Напишите функцию, определя...   \n",
       "\n",
       "                                                chosen  \\\n",
       "253  [{'role': 'system', 'content': '\\n\\n###INSTRUC...   \n",
       "96   [{'role': 'system', 'content': '\\n\\n###INSTRUC...   \n",
       "\n",
       "                                              rejected  \\\n",
       "253  [{'role': 'system', 'content': '\\n\\n###INSTRUC...   \n",
       "96   [{'role': 'system', 'content': '\\n\\n###INSTRUC...   \n",
       "\n",
       "                                              messages  \n",
       "253  [{'role': 'system', 'content': '\\n\\n###INSTRUC...  \n",
       "96   [{'role': 'system', 'content': '\\n\\n###INSTRUC...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences_dpo_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zU2oQLLx9TkH"
   },
   "outputs": [],
   "source": [
    "preferences_dpo_df.to_csv('preferences_dpo_final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NaWj7c6GsSz"
   },
   "source": [
    "## DPO Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RgIGsBqe9TmG"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import pipeline, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import peft\n",
    "import transformers\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W2J5rptd9Tor"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(preferences_dpo_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEg8VP2l9TrY",
    "outputId": "be73d158-c60a-4e3d-9b40-8dcbe275caff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'messages'],\n",
       "    num_rows: 347\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 17 17:24:27 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              80W / 700W |      2MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              76W / 700W |      2MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMSrswH29TuL",
    "outputId": "da3f4480-7b5f-4e71-8db5-36833ce350eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d7370d819d4b1483e11e8ff37846a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    device_map='balanced',\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, tokenizer, train_dataset = accelerator.prepare(model, tokenizer, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "I5EZeJJBMavJ",
    "outputId": "e4a045e8-d7d5-47fd-e3bc-f480fdb30c11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Я — цифровой помощник, созданный для того, чтобы помогать пользователям, отвечая на их вопросы и выполняя различные задачи.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "system_prompt = \"You are a helpful assistant, just answer user's questions.\"\n",
    "prompt = 'Кто ты?'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "answer = pipe(messages, max_length=6048)[0]['generated_text'][-1]['content']\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHD4-MdMRYLO",
    "outputId": "67297334-34ce-4d3a-f1fb-b4162e71c15d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "model.layers.32.self_attn.q_proj.weight\n",
      "model.layers.32.self_attn.k_proj.weight\n",
      "model.layers.32.self_attn.v_proj.weight\n",
      "model.layers.32.self_attn.o_proj.weight\n",
      "model.layers.32.mlp.gate_proj.weight\n",
      "model.layers.32.mlp.up_proj.weight\n",
      "model.layers.32.mlp.down_proj.weight\n",
      "model.layers.32.input_layernorm.weight\n",
      "model.layers.32.post_attention_layernorm.weight\n",
      "model.layers.33.self_attn.q_proj.weight\n",
      "model.layers.33.self_attn.k_proj.weight\n",
      "model.layers.33.self_attn.v_proj.weight\n",
      "model.layers.33.self_attn.o_proj.weight\n",
      "model.layers.33.mlp.gate_proj.weight\n",
      "model.layers.33.mlp.up_proj.weight\n",
      "model.layers.33.mlp.down_proj.weight\n",
      "model.layers.33.input_layernorm.weight\n",
      "model.layers.33.post_attention_layernorm.weight\n",
      "model.layers.34.self_attn.q_proj.weight\n",
      "model.layers.34.self_attn.k_proj.weight\n",
      "model.layers.34.self_attn.v_proj.weight\n",
      "model.layers.34.self_attn.o_proj.weight\n",
      "model.layers.34.mlp.gate_proj.weight\n",
      "model.layers.34.mlp.up_proj.weight\n",
      "model.layers.34.mlp.down_proj.weight\n",
      "model.layers.34.input_layernorm.weight\n",
      "model.layers.34.post_attention_layernorm.weight\n",
      "model.layers.35.self_attn.q_proj.weight\n",
      "model.layers.35.self_attn.k_proj.weight\n",
      "model.layers.35.self_attn.v_proj.weight\n",
      "model.layers.35.self_attn.o_proj.weight\n",
      "model.layers.35.mlp.gate_proj.weight\n",
      "model.layers.35.mlp.up_proj.weight\n",
      "model.layers.35.mlp.down_proj.weight\n",
      "model.layers.35.input_layernorm.weight\n",
      "model.layers.35.post_attention_layernorm.weight\n",
      "model.layers.36.self_attn.q_proj.weight\n",
      "model.layers.36.self_attn.k_proj.weight\n",
      "model.layers.36.self_attn.v_proj.weight\n",
      "model.layers.36.self_attn.o_proj.weight\n",
      "model.layers.36.mlp.gate_proj.weight\n",
      "model.layers.36.mlp.up_proj.weight\n",
      "model.layers.36.mlp.down_proj.weight\n",
      "model.layers.36.input_layernorm.weight\n",
      "model.layers.36.post_attention_layernorm.weight\n",
      "model.layers.37.self_attn.q_proj.weight\n",
      "model.layers.37.self_attn.k_proj.weight\n",
      "model.layers.37.self_attn.v_proj.weight\n",
      "model.layers.37.self_attn.o_proj.weight\n",
      "model.layers.37.mlp.gate_proj.weight\n",
      "model.layers.37.mlp.up_proj.weight\n",
      "model.layers.37.mlp.down_proj.weight\n",
      "model.layers.37.input_layernorm.weight\n",
      "model.layers.37.post_attention_layernorm.weight\n",
      "model.layers.38.self_attn.q_proj.weight\n",
      "model.layers.38.self_attn.k_proj.weight\n",
      "model.layers.38.self_attn.v_proj.weight\n",
      "model.layers.38.self_attn.o_proj.weight\n",
      "model.layers.38.mlp.gate_proj.weight\n",
      "model.layers.38.mlp.up_proj.weight\n",
      "model.layers.38.mlp.down_proj.weight\n",
      "model.layers.38.input_layernorm.weight\n",
      "model.layers.38.post_attention_layernorm.weight\n",
      "model.layers.39.self_attn.q_proj.weight\n",
      "model.layers.39.self_attn.k_proj.weight\n",
      "model.layers.39.self_attn.v_proj.weight\n",
      "model.layers.39.self_attn.o_proj.weight\n",
      "model.layers.39.mlp.gate_proj.weight\n",
      "model.layers.39.mlp.up_proj.weight\n",
      "model.layers.39.mlp.down_proj.weight\n",
      "model.layers.39.input_layernorm.weight\n",
      "model.layers.39.post_attention_layernorm.weight\n",
      "model.norm.weight\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Q0RMmduAQH_v"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    use_dora=True,\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_dropout=0.2,\n",
    "    bias='none',\n",
    "    layers_to_transform=[38, 39],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "#peft_model = get_peft_model(model, peft_config).to('сuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YU0pn63gcJKz",
    "outputId": "7534d303-f8e3-48f2-9bca-346d04b7451b"
   },
   "outputs": [],
   "source": [
    "#peft_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "d04f1e30b5674a66896fd4d7345d814b",
      "83c909f6ea724db88047595ab1b1a063",
      "ae415eb1770448318497619b2f598b2a",
      "22a9300f49154e85a108bd20189c762e",
      "1ac03c5bc42847f092d231d3c401a05c",
      "61153b8463664ea6a02ce511686e4a49",
      "70dba985c09641f39b1f11d57b80d14c",
      "cd825e2bf0504c06885ae3e060a9b69b",
      "0b20c054570047e58b56b8ba803111f2",
      "a3b6328ef1db4d35a2d3f7de26f0589d",
      "d2f5e22a795841da91cabff6bca7a917"
     ]
    },
    "id": "NnIEWGgjTqk3",
    "outputId": "9f4ab992-139c-4cb2-929a-fd08c195dc88"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0f9abca0914866a319d506678dc6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 331\n",
      "p95 prompt length: 1466\n",
      "p95 prompt + chosen length: 4514\n"
     ]
    }
   ],
   "source": [
    "from numpy import percentile\n",
    "\n",
    "prompt_length = int(percentile([len(tokenizer(x)[\"input_ids\"]) for x in train_dataset[\"prompt\"]], 95))\n",
    "max_seq_length_chosen = int(percentile([len(tokenizer(x[\"prompt\"] + x[\"chosen\"])[\"input_ids\"]) for x in train_dataset], 95))\n",
    "max_seq_length_rejected = int(percentile([len(tokenizer(x[\"prompt\"] + x[\"rejected\"])[\"input_ids\"]) for x in train_dataset], 95))\n",
    "max_seq_length = max(max_seq_length_chosen, max_seq_length_rejected)\n",
    "\n",
    "train_dataset = train_dataset.filter(lambda x: len(tokenizer(x[\"prompt\"] + x[\"chosen\"])[\"input_ids\"]) <= max_seq_length)\n",
    "print(f\"len(train_dataset): {len(train_dataset)}\")\n",
    "\n",
    "prompt_length = ((prompt_length + 1) // 2) * 2\n",
    "max_seq_length = ((max_seq_length + 1) // 2) * 2\n",
    "print(f\"p95 prompt length: {prompt_length}\")\n",
    "print(f\"p95 prompt + chosen length: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nJpA8JIGT-Az"
   },
   "outputs": [],
   "source": [
    "prompt_length = 1466\n",
    "max_seq_length = 4514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xA5yW8BLR29K"
   },
   "outputs": [],
   "source": [
    "training_args = DPOConfig(\n",
    "    output_dir=\"DPO_res\",\n",
    "    #num_train_epochs=1,\n",
    "    max_steps=20, ################## TUNE\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    learning_rate=5e-5,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=1,\n",
    "    save_steps=10,\n",
    "    save_total_limit=10,\n",
    "    bf16=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    use_cpu=False,\n",
    "    remove_unused_columns=False,\n",
    "    max_length=max_seq_length,\n",
    "    max_prompt_length=prompt_length,\n",
    ")\n",
    "\n",
    "dpo_args = {\n",
    "    \"beta\": 0.1,\n",
    "    \"loss_type\": \"sigmoid\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "a05005cba0134e71ab3c27b49fbe8e56",
      "c21588bf78fe42fea3beb97761453758",
      "39cdcc8b5c4840638caf6466facf18a0",
      "d580db0223ce49029c23408312074235",
      "fd6e2798ba53421b857f41eab4174ede",
      "2148ff9d584842f3807976a73a159b50",
      "bb994987aa01437f961e2300804efd22",
      "fbc917d8bb3e4a069233459866839d15",
      "3329880c492e4eb296583d04d16d172d",
      "a1d0b1eb684c47d2bf9b5690bac4c706",
      "a6c5371006294c6d88b76b58ede3545a"
     ]
    },
    "id": "PL_4_I99TTo9",
    "outputId": "472b5e77-5c80-454a-f8d7-0cbd010cec0a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d673941ad694b62bae97dbba8502774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    beta=dpo_args[\"beta\"],\n",
    "    #loss_type=dpo_args[\"loss_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "JRLu1fxN9Tza",
    "outputId": "df83a0f2-2185-4055-a2df-89fba1f383f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 07:19, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.688300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.646200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.423100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.380100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.340500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.323700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.314900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.4962386041879654, metrics={'train_runtime': 464.0325, 'train_samples_per_second': 0.345, 'train_steps_per_second': 0.043, 'total_flos': 0.0, 'train_loss': 0.4962386041879654, 'epoch': 0.4819277108433735})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator.wait_for_everyone()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtmPtt4K9T4t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50aD0mpU9T7M"
   },
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PQ-aS1iw9T90"
   },
   "outputs": [],
   "source": [
    "final_test_df = pd.read_csv(path + 'test_database.csv')\n",
    "test_solutions = pd.read_excel(path + 'test/solutions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7mXY4e459UAX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119, 9), (325, 5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.shape, test_solutions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ciaFdxWN9UC1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>student_solution</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>author_comment_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>584</td>\n",
       "      <td>36</td>\n",
       "      <td>time = input()\\n\\n# ваш код ниже\\n\\nprint(f'В ...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>279</td>\n",
       "      <td>17</td>\n",
       "      <td>room = input()\\n\\nresidences = []\\nfor key, va...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  task_id                                   student_solution  \\\n",
       "234  584       36  time = input()\\n\\n# ваш код ниже\\n\\nprint(f'В ...   \n",
       "110  279       17  room = input()\\n\\nresidences = []\\nfor key, va...   \n",
       "\n",
       "        author_comment  author_comment_embedding  \n",
       "234  Ваше предсказание                       NaN  \n",
       "110  Ваше предсказание                       NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_solutions.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "v6lOl_7P9UFm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>task_id</th>\n",
       "      <th>type</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>level</th>\n",
       "      <th>description</th>\n",
       "      <th>author_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>closed</td>\n",
       "      <td>антитезы</td>\n",
       "      <td>Сегодня мы будем анализировать антитезы в тексте!</td>\n",
       "      <td>B</td>\n",
       "      <td>Реализуйте программу, которая напечатает анали...</td>\n",
       "      <td>ton = input()\\n\\n# ваш код ниже\\n\\nprint(f\"Сег...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>open</td>\n",
       "      <td>неделю</td>\n",
       "      <td>В агентстве «Шедеврус» мы делаем дизайн за нед...</td>\n",
       "      <td>B</td>\n",
       "      <td>Реализуйте следующую программу: \\n\\nВ переменн...</td>\n",
       "      <td>time = input()\\n\\n# ваш код ниже\\n\\nprint(f'В ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  number  task_id    type     input  \\\n",
       "73  141       3       24  closed  антитезы   \n",
       "91  198       0       36    open    неделю   \n",
       "\n",
       "                                               output level  \\\n",
       "73  Сегодня мы будем анализировать антитезы в тексте!     B   \n",
       "91  В агентстве «Шедеврус» мы делаем дизайн за нед...     B   \n",
       "\n",
       "                                          description  \\\n",
       "73  Реализуйте программу, которая напечатает анали...   \n",
       "91  Реализуйте следующую программу: \\n\\nВ переменн...   \n",
       "\n",
       "                                      author_solution  \n",
       "73  ton = input()\\n\\n# ваш код ниже\\n\\nprint(f\"Сег...  \n",
       "91  time = input()\\n\\n# ваш код ниже\\n\\nprint(f'В ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DxdiA5N29UId"
   },
   "outputs": [],
   "source": [
    "new_test_df = {'id': [], 'task_id': [], 'description': [],\n",
    "          'input': [], 'output': [], 'student_solution': [],\n",
    "          'author_solution': [], 'author_comment': [], 'type': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "41O7wrYh9UKt"
   },
   "outputs": [],
   "source": [
    "for index, row in test_solutions.iterrows():\n",
    "    new_test_df['id'].append(row['id'])\n",
    "    new_test_df['task_id'].append(row['task_id'])\n",
    "    new_test_df['student_solution'].append(row['student_solution'])\n",
    "    new_test_df['author_comment'].append('')\n",
    "    inp = final_test_df[final_test_df['task_id'] == row['task_id']]['input'].tolist()\n",
    "    out = final_test_df[final_test_df['task_id'] == row['task_id']]['output'].tolist()\n",
    "    new_test_df['input'].append(inp)\n",
    "    new_test_df['output'].append(out)\n",
    "    test_type = final_test_df[final_test_df['task_id'] == row['task_id']]['type'].tolist()\n",
    "    new_test_df['type'].append(test_type)\n",
    "    description = final_test_df[final_test_df['task_id'] == row['task_id']]['description'].tolist()[0]\n",
    "    new_test_df['description'].append(description)\n",
    "    author_solution = final_test_df[final_test_df['task_id'] == row['task_id']]['author_solution'].tolist()[0]\n",
    "    new_test_df['author_solution'].append(author_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wODGz0Gn9UNm"
   },
   "outputs": [],
   "source": [
    "new_test_df = pd.DataFrame(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-pc6qut_9UQc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "5l6CKVqW9UTL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>description</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>student_solution</th>\n",
       "      <th>author_solution</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>499</td>\n",
       "      <td>31</td>\n",
       "      <td>Роман анализирует информаицю о переведенных те...</td>\n",
       "      <td>[75000, 82100, 30000, 1000000]</td>\n",
       "      <td>[2004,французский,иврит,78918 слов\\n1998,франц...</td>\n",
       "      <td>words = int(input())\\n\\nwith open('info_texts....</td>\n",
       "      <td>words = int(input())\\n\\nwith open('info_texts....</td>\n",
       "      <td></td>\n",
       "      <td>[open, closed, closed, closed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>523</td>\n",
       "      <td>33</td>\n",
       "      <td>Игорь хочет пойти работать по профессии и смот...</td>\n",
       "      <td>[Организатор международных мероприятий: управл...</td>\n",
       "      <td>[Организатор международных мероприятий; Аккаун...</td>\n",
       "      <td>data = input().split('/ ')\\nskill = input()\\n\\...</td>\n",
       "      <td>data = input().split('/ ')\\nskill = input()\\n\\...</td>\n",
       "      <td></td>\n",
       "      <td>[open, open, open, closed, closed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  task_id                                        description  \\\n",
       "207  499       31  Роман анализирует информаицю о переведенных те...   \n",
       "213  523       33  Игорь хочет пойти работать по профессии и смот...   \n",
       "\n",
       "                                                 input  \\\n",
       "207                     [75000, 82100, 30000, 1000000]   \n",
       "213  [Организатор международных мероприятий: управл...   \n",
       "\n",
       "                                                output  \\\n",
       "207  [2004,французский,иврит,78918 слов\\n1998,франц...   \n",
       "213  [Организатор международных мероприятий; Аккаун...   \n",
       "\n",
       "                                      student_solution  \\\n",
       "207  words = int(input())\\n\\nwith open('info_texts....   \n",
       "213  data = input().split('/ ')\\nskill = input()\\n\\...   \n",
       "\n",
       "                                       author_solution author_comment  \\\n",
       "207  words = int(input())\\n\\nwith open('info_texts....                  \n",
       "213  data = input().split('/ ')\\nskill = input()\\n\\...                  \n",
       "\n",
       "                                   type  \n",
       "207      [open, closed, closed, closed]  \n",
       "213  [open, open, open, closed, closed]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_prompt = []\n",
    "for index, row in new_test_df.iterrows():\n",
    "  description = row['description']\n",
    "  res = []\n",
    "  for i in range(len(row['input'])):\n",
    "    res.append(f\"\\n<Example {i+1}>: \\n<Тип теста {i+1}>: {row['type'][i]} \\n<Ввод>: {row['input'][i]} \\n<Вывод>: {row['output'][i]}\")\n",
    "  result = ' '.join(res)\n",
    "  student_solution = row['student_solution']\n",
    "  author_solution = row['author_solution']\n",
    "  author_comment = row['author_comment']\n",
    "  prompt = f\"<Task description>: {description} {result} \\n<Решение студента>: {student_solution} \\n<Идеальное решение>: {author_solution} \\n\\n\\n<Комментарий эксперта>: {author_comment}\"\n",
    "  final_test_prompt.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df['prompt'] = final_test_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>description</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>student_solution</th>\n",
       "      <th>author_solution</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>359</td>\n",
       "      <td>22</td>\n",
       "      <td>Напишите функцию, определяющую возьмут ли диза...</td>\n",
       "      <td>[{\\n    'AltAirResidence': (3000000, 'не реали...</td>\n",
       "      <td>[[42000000, False], [1000000, True], [160000, ...</td>\n",
       "      <td>def work(slov):\\n    counter = 0\\n    money_do...</td>\n",
       "      <td>def work(slov):\\n    counter = 0\\n    money_do...</td>\n",
       "      <td></td>\n",
       "      <td>[open, open, open, closed, closed, closed, clo...</td>\n",
       "      <td>&lt;Task description&gt;: Напишите функцию, определя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>309</td>\n",
       "      <td>19</td>\n",
       "      <td>Ксения анализирует реализованные дизайн-проект...</td>\n",
       "      <td>[20, 40, 8, 15, 43]</td>\n",
       "      <td>[2019,178 тыс. руб.,9 недель\\n2022,180 тыс. ру...</td>\n",
       "      <td>week = int(input())\\n\\nwith open('projects_fil...</td>\n",
       "      <td>week = int(input())\\n\\nwith open('projects_fil...</td>\n",
       "      <td></td>\n",
       "      <td>[open, closed, closed, closed, closed]</td>\n",
       "      <td>&lt;Task description&gt;: Ксения анализирует реализо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  task_id                                        description  \\\n",
       "157  359       22  Напишите функцию, определяющую возьмут ли диза...   \n",
       "123  309       19  Ксения анализирует реализованные дизайн-проект...   \n",
       "\n",
       "                                                 input  \\\n",
       "157  [{\\n    'AltAirResidence': (3000000, 'не реали...   \n",
       "123                                [20, 40, 8, 15, 43]   \n",
       "\n",
       "                                                output  \\\n",
       "157  [[42000000, False], [1000000, True], [160000, ...   \n",
       "123  [2019,178 тыс. руб.,9 недель\\n2022,180 тыс. ру...   \n",
       "\n",
       "                                      student_solution  \\\n",
       "157  def work(slov):\\n    counter = 0\\n    money_do...   \n",
       "123  week = int(input())\\n\\nwith open('projects_fil...   \n",
       "\n",
       "                                       author_solution author_comment  \\\n",
       "157  def work(slov):\\n    counter = 0\\n    money_do...                  \n",
       "123  week = int(input())\\n\\nwith open('projects_fil...                  \n",
       "\n",
       "                                                  type  \\\n",
       "157  [open, open, open, closed, closed, closed, clo...   \n",
       "123             [open, closed, closed, closed, closed]   \n",
       "\n",
       "                                                prompt  \n",
       "157  <Task description>: Напишите функцию, определя...  \n",
       "123  <Task description>: Ксения анализирует реализо...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Task description>: Реализуйте программу, которая напечатает стоимость реализации проекта со скидкой: \n",
      "\n",
      "В переменную dicount считывается размер скидки на реализацию проекта (вещественное число). Этот код уже написан.\n",
      "В переменную money считывается стоимость реализации проекта в тысячах (целое число). Этот код уже написан.\n",
      "Программа должна вывести фразу вида 'Реализация проекта будет стоить <стоимость> тыс. руб. без скидки. Со скидой стоимость составит <стоимость с учетом скидки> тыс. руб.'. \n",
      "Важно! В коде обязательно нужно использовать f-строку! \n",
      "<Example 1>: \n",
      "<Тип теста 1>: open \n",
      "<Ввод>: 0.1; 500 \n",
      "<Вывод>: Реализация проекта будет стоить 500 тыс. руб. без скидки. Со скидкой стоимость составит 450.0 тыс. руб. \n",
      "<Example 2>: \n",
      "<Тип теста 2>: open \n",
      "<Ввод>: 0.05; 900000 \n",
      "<Вывод>: Реализация проекта будет стоить 900000 тыс. руб. без скидки. Со скидкой стоимость составит 855000.0 тыс. руб. \n",
      "<Example 3>: \n",
      "<Тип теста 3>: open \n",
      "<Ввод>: 0; 2345678 \n",
      "<Вывод>: Реализация проекта будет стоить 2345678 тыс. руб. без скидки. Со скидкой стоимость составит 2345678.0 тыс. руб. \n",
      "<Example 4>: \n",
      "<Тип теста 4>: closed \n",
      "<Ввод>: 0.5; 100 \n",
      "<Вывод>: Реализация проекта будет стоить 100 тыс. руб. без скидки. Со скидкой стоимость составит 50.0 тыс. руб. \n",
      "<Example 5>: \n",
      "<Тип теста 5>: closed \n",
      "<Ввод>: 0.003; 12345667 \n",
      "<Вывод>: Реализация проекта будет стоить 12345667 тыс. руб. без скидки. Со скидкой стоимость составит 12308629.999 тыс. руб. \n",
      "<Решение студента>: discount  = float(input())\n",
      "money = int(input())\n",
      "\n",
      "#ваш код ниже\n",
      "\n",
      "print('Реализация проекта будет стоить {money} тыс. руб. без скидки. Со скидой стоимость составит {money- (money * discount)} тыс. руб.') \n",
      "<Идеальное решение>: discount  = float(input())\n",
      "money = int(input())\n",
      "\n",
      "#ваш код ниже\n",
      "\n",
      "print(f'Реализация проекта будет стоить {money} тыс. руб. без скидки. Со скидой стоимость составит {money- (money * discount)} тыс. руб.') \n",
      "\n",
      "\n",
      "<Комментарий эксперта>: \n"
     ]
    }
   ],
   "source": [
    "print(new_test_df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df.to_csv('new_test_df_for_inference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Комментарий эксперта>: В вашем решении есть небольшая ошибка в расчете стоимости со скидкой. Вы вычитаете из исходной стоимости произведение стоимости на скидку, что неверно. Правильно будет умножить исходную стоимость на (1 - скидку), чтобы получить стоимость со скидкой.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "###INSTRUCTIONS###\n",
    "\n",
    "You MUST ALWAYS:\n",
    "- Answer in russian language\n",
    "- I have no fingers and the placeholders trauma. NEVER use placeholders or omit the code\n",
    "- You will be PENALIZED for wrong answers\n",
    "- NEVER HALLUCINATE\n",
    "- You DENIED to overlook the critical context\n",
    "- ALWAYS follow ###Answering rules###\n",
    "\n",
    "###Answering Rules###\n",
    "\n",
    "Follow in the strict order:\n",
    "\n",
    "1. USE the language of my message\n",
    "2. You MUST combine your deep knowledge of the topic and clear thinking to quickly and accurately decipher the answer step-by-step with CONCRETE details\n",
    "3. I'm going to tip $1,000,000 for the best reply\n",
    "4. Your answer is critical for my career\n",
    "5. Answer the question in a natural, human-like manner\n",
    "\n",
    "You are a world-famous expert in teaching, known for your ability to deeply understand your students' thought processes and guide them toward the correct solutions. Your role is to receive solutions to problems from a student, analyze their approach, and provide thoughtful, personalized feedback. Your focus is on helping the student understand where they might have made a mistake or overlooked something without giving away the correct answer directly. Write directly where the mistake is. Do not write a long answer. Provide only a hint that guides the student in the right direction, without giving away the full solution. People should not guess that you are an AI. We will break the problem into smaller steps and focus on understanding each part by comparing the student's solution with the ideal one.\n",
    "\n",
    "###CHAIN OF THOUGHT###\n",
    "\n",
    "1. Clarify the Task: Restate the problem in simpler terms, focusing on what the student is trying to achieve.\n",
    "2. Compare the Solutions: Directly compare the student's solution with the ideal solution:\n",
    "   - Step 1: Analyze the input handling in both solutions. Are there any differences?\n",
    "   - Step 2: Compare how conditions are checked in the student’s code versus the ideal solution. What differences do you observe?\n",
    "   - Step 3: Identify specific points where the student’s logic deviates from the ideal solution.\n",
    "3. Spot the Issue: Pinpoint where the logic in the student’s solution is incorrect:\n",
    "   - {Provide a hint about the nature of the error without giving away the solution}.\n",
    "4. Suggest an Improvement: Offer guidance on how to adjust the code to match the logic of the ideal solution, emphasizing where changes should be made.\n",
    "\n",
    "Remember, making mistakes is part of learning. Think about each step carefully, and let’s find the best way to improve.\n",
    "Example:\n",
    "(Your task is to respond just as concisely and without giving the exact solution, like after <Expert's Comment>:): <Task description>: Реализуйте программу, которая напечатает хэштеги из фраз для лендинга сайта: \\n\\nВ переменную logo считывается текст лендинга. Этот код уже написан.\\nПрограмма проверяет, есть ли в этом тексте хэштеги.  Хэштегами можно считать все элементы, которые начинаются со знака \"#\" и которые не состоят только из цифр (не включая знак \"#\"). Гарантируется, что хэштеги отделены от другого текста пробелом. \\nВ конце программа печатает все хэштеги через запятую с пробелом. Хэштеги выводятся в том же порядке, в котором они идут в тексте.\\nЕсли знаков хэштегов в тексте нет, то программа ничего не печатает. \\n<Example 1>: \\n<Тип теста 1>: open \\n<Ввод>: Выучите китайский язык без усилий выполняя задания в приложении ( #the_best_app ) за #20 дней. \\n<Вывод>: #the_best_app \\n<Example 2>: \\n<Тип теста 2>: open \\n<Ввод>: Ваш вопрос ( #question ) - наш ответ ( #answer ) ! Мы всегда с Вами yf #100 % \\n<Вывод>: #question, #answer \\n<Example 3>: \\n<Тип теста 3>: open \\n<Ввод>: Мощный рывок для Вашего @бизнеса \\n<Вывод>: nan \\n<Example 4>: \\n<Тип теста 4>: closed \\n<Ввод>: Я никогда не был #счастье1 #любовь123 #123_123 qwe#qwe \\n<Вывод>: #счастье1, #любовь123, #123_123 \\n<Example 5>: \\n<Тип теста 5>: closed \\n<Ввод>: 9 из 10 экспертов рекомендуют # наш #_1223 продукт #__ . \\n<Вывод>: #, #_1223, #__ \\n<Example 6>: \\n<Тип теста 6>: closed \\n<Ввод>: # #123 #qswr_1 @qws1 $1#qwd 1#123_qwe #0 #____ #$567123 \\n<Вывод>: #, #qswr_1, #____, #$567123 \\n<Решение студента>: logo = input()\\n\\nres = []\\nfor info in logo.split:\\n    if info.startswith(\\'#\\') and info[1:].isdigit() == False:      \\n        res.append(info)\\n        \\nprint(*res, sep=\\', \\') \\n<Идеальное решение>: logo = input()\\n\\nres = []\\nfor info in logo.split():\\n    if info.startswith(\\'#\\') and info[1:].isdigit() == False:      \\n        res.append(info)\\n        \\nprint(*res, sep=\\', \\') \\n\\n\\n<Комментарий эксперта>: Вы забыли поставить скобки в методе .split().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = new_test_df['prompt'][0]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "answer = pipe(messages, max_length=4096, max_new_tokens=200)[0]['generated_text'][-1]['content']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:38, 19.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# TEST inference\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "###INSTRUCTIONS###\n",
    "\n",
    "You MUST ALWAYS:\n",
    "- Answer in russian language\n",
    "- I have no fingers and the placeholders trauma. NEVER use placeholders or omit the code\n",
    "- You will be PENALIZED for wrong answers\n",
    "- NEVER HALLUCINATE\n",
    "- You DENIED to overlook the critical context\n",
    "- ALWAYS follow ###Answering rules###\n",
    "\n",
    "###Answering Rules###\n",
    "\n",
    "Follow in the strict order:\n",
    "\n",
    "1. USE the language of my message\n",
    "2. You MUST combine your deep knowledge of the topic and clear thinking to quickly and accurately decipher the answer step-by-step with CONCRETE details\n",
    "3. I'm going to tip $1,000,000 for the best reply\n",
    "4. Your answer is critical for my career\n",
    "5. Answer the question in a natural, human-like manner\n",
    "\n",
    "You are a world-famous expert in teaching, known for your ability to deeply understand your students' thought processes and guide them toward the correct solutions. Your role is to receive solutions to problems from a student, analyze their approach, and provide thoughtful, personalized feedback. Your focus is on helping the student understand where they might have made a mistake or overlooked something without giving away the correct answer directly. Write directly where the mistake is. Do not write a long answer. Provide only a hint that guides the student in the right direction, without giving away the full solution. People should not guess that you are an AI. We will break the problem into smaller steps and focus on understanding each part by comparing the student's solution with the ideal one.\n",
    "\n",
    "###CHAIN OF THOUGHT###\n",
    "\n",
    "1. Clarify the Task: Restate the problem in simpler terms, focusing on what the student is trying to achieve.\n",
    "2. Compare the Solutions: Directly compare the student's solution with the ideal solution:\n",
    "   - Step 1: Analyze the input handling in both solutions. Are there any differences?\n",
    "   - Step 2: Compare how conditions are checked in the student’s code versus the ideal solution. What differences do you observe?\n",
    "   - Step 3: Identify specific points where the student’s logic deviates from the ideal solution.\n",
    "3. Spot the Issue: Pinpoint where the logic in the student’s solution is incorrect:\n",
    "   - {Provide a hint about the nature of the error without giving away the solution}.\n",
    "4. Suggest an Improvement: Offer guidance on how to adjust the code to match the logic of the ideal solution, emphasizing where changes should be made.\n",
    "\n",
    "Remember, making mistakes is part of learning. Think about each step carefully, and let’s find the best way to improve.\n",
    "Example:\n",
    "(Your task is to respond just as concisely and without giving the exact solution, like after <Expert's Comment>:): <Task description>: Реализуйте программу, которая напечатает хэштеги из фраз для лендинга сайта: \\n\\nВ переменную logo считывается текст лендинга. Этот код уже написан.\\nПрограмма проверяет, есть ли в этом тексте хэштеги.  Хэштегами можно считать все элементы, которые начинаются со знака \"#\" и которые не состоят только из цифр (не включая знак \"#\"). Гарантируется, что хэштеги отделены от другого текста пробелом. \\nВ конце программа печатает все хэштеги через запятую с пробелом. Хэштеги выводятся в том же порядке, в котором они идут в тексте.\\nЕсли знаков хэштегов в тексте нет, то программа ничего не печатает. \\n<Example 1>: \\n<Тип теста 1>: open \\n<Ввод>: Выучите китайский язык без усилий выполняя задания в приложении ( #the_best_app ) за #20 дней. \\n<Вывод>: #the_best_app \\n<Example 2>: \\n<Тип теста 2>: open \\n<Ввод>: Ваш вопрос ( #question ) - наш ответ ( #answer ) ! Мы всегда с Вами yf #100 % \\n<Вывод>: #question, #answer \\n<Example 3>: \\n<Тип теста 3>: open \\n<Ввод>: Мощный рывок для Вашего @бизнеса \\n<Вывод>: nan \\n<Example 4>: \\n<Тип теста 4>: closed \\n<Ввод>: Я никогда не был #счастье1 #любовь123 #123_123 qwe#qwe \\n<Вывод>: #счастье1, #любовь123, #123_123 \\n<Example 5>: \\n<Тип теста 5>: closed \\n<Ввод>: 9 из 10 экспертов рекомендуют # наш #_1223 продукт #__ . \\n<Вывод>: #, #_1223, #__ \\n<Example 6>: \\n<Тип теста 6>: closed \\n<Ввод>: # #123 #qswr_1 @qws1 $1#qwd 1#123_qwe #0 #____ #$567123 \\n<Вывод>: #, #qswr_1, #____, #$567123 \\n<Решение студента>: logo = input()\\n\\nres = []\\nfor info in logo.split:\\n    if info.startswith(\\'#\\') and info[1:].isdigit() == False:      \\n        res.append(info)\\n        \\nprint(*res, sep=\\', \\') \\n<Идеальное решение>: logo = input()\\n\\nres = []\\nfor info in logo.split():\\n    if info.startswith(\\'#\\') and info[1:].isdigit() == False:      \\n        res.append(info)\\n        \\nprint(*res, sep=\\', \\') \\n\\n\\n<Комментарий эксперта>: Вы забыли поставить скобки в методе .split().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "answers_test = []\n",
    "for index, row in tqdm(new_test_df.iloc[:5].iterrows()):\n",
    "  prompt = row['prompt']\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "  answer = pipe(messages, max_length=6048)[0]['generated_text'][-1]['content']\n",
    "  answers_test.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_test = pd.DataFrame(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Комментарий эксперта&gt;: В вашем решении есть н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Комментарий эксперта&gt;: Вы не закрыли скобку в...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "2  <Комментарий эксперта>: В вашем решении есть н...\n",
       "1  <Комментарий эксперта>: Вы не закрыли скобку в..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0)  <Комментарий эксперта>: В вашем решении есть небольшая ошибка в расчете стоимости со скидкой. Вы вычитаете из исходной стоимости произведение стоимости на скидку, что неверно. Правильно будет умножить исходную стоимость на (1 - скидку), чтобы получить стоимость со скидкой.\n",
      "1)  <Комментарий эксперта>: Вы не закрыли скобку в конце строки вывода, что приведет к ошибке. Кроме того, в вычислении стоимости с учетом скидки вы использовали неверную операцию. Вместо вычитания нужно умножить стоимость проекта на скидку и вычесть полученное значение из исходной стоимости. Также стоит добавить форматирование числа с двумя знаками после запятой для точности.\n",
      "2)  <Комментарий эксперта>: В вашем решении есть небольшая ошибка в вычислении стоимости проекта со скидкой. Вы вычитаете из стоимости проекта произведение стоимости на скидку, что неверно. Вместо этого нужно умножить стоимость проекта на (1 минус скидку), чтобы получить стоимость со скидкой. Исправьте эту часть кода, и ваше решение будет правильным.\n",
      "3)  <Комментарий эксперта>: Вы неправильно использовали переменную `discount` в вычислении стоимости со скидкой. Вместо того чтобы вычесть произведение стоимости проекта на скидку, вы пытаетесь вычесть это из самой стоимости проекта, что приведет к ошибке типов данных. Вам нужно умножить стоимость проекта на скидку в виде десятичной дроби и вычесть полученное значение из исходной стоимости. Кроме того, в выводе вы использовали переменную `discount` вместо `money`, что также является ошибкой.\n",
      "4)  <Комментарий эксперта>: Вы правильно использовали f-строку для форматирования вывода, но в вашем решении есть ошибка в логике расчета стоимости со скидкой. Вместо того чтобы умножать общую стоимость на скидку, вам нужно вычесть произведение стоимости на скидку из исходной стоимости, чтобы получить стоимость со скидкой.\n"
     ]
    }
   ],
   "source": [
    "for index, row in answer_test.iterrows():\n",
    "    print(f'{index}) ', row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('20_steps_dpo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "print(\"Loading models...\", end=\"\")\n",
    "model_name = \"DeepPavlov/rubert-base-cased-sentence\"\n",
    "emb_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "emb_model = BertModel.from_pretrained(model_name)\n",
    "print(\"OK\")\n",
    "\n",
    "\n",
    "def get_sentence_embedding(sentence: str) -> torch.Tensor:\n",
    "    inputs = emb_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = emb_model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def string2embedding(string: str) -> torch.Tensor:\n",
    "    return torch.Tensor([float(i) for i in string.split()])\n",
    "\n",
    "\n",
    "def embedding2string(embedding: torch.Tensor) -> str:\n",
    "    return \" \".join([str(i) for i in embedding.tolist()])\n",
    "\n",
    "\n",
    "def generate_submit(test_solutions: str, predict_func: Callable, save_path: str, use_tqdm: bool = True) -> None:\n",
    "    bar = range(len(test_solutions))\n",
    "    if use_tqdm:\n",
    "        import tqdm\n",
    "\n",
    "        bar = tqdm.tqdm(bar, desc=\"Predicting\")\n",
    "\n",
    "    submit_df = pd.DataFrame(columns=[\"solution_id\", \"author_comment\", \"author_comment_embedding\"])\n",
    "    for i in bar:\n",
    "        idx = test_solutions.id.iloc[i]\n",
    "        solution_row = test_solutions.prompt.iloc[i]\n",
    "        text = predict_func(solution_row)  # here you can do absolute whatever you want\n",
    "        embedding = embedding2string(get_sentence_embedding(text))\n",
    "        submit_df.loc[i] = [idx, text, embedding]\n",
    "    submit_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    answer = pipe(messages, max_length=6048)[0]['generated_text'][-1]['content']\n",
    "    #if '<Комментарий эксперта>:' in answer:\n",
    "    #    answer = answer[24:] ########################\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submit(\n",
    "        test_solutions=new_test_df,\n",
    "        predict_func=predict,\n",
    "        save_path=\"submit5_emae.csv\",\n",
    "        use_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + \"submit5_emae.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrA2NQLN9UVx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTS8DeF-9UYP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JXpt_o49UdI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiTyQWyX9Uft"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b20c054570047e58b56b8ba803111f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ac03c5bc42847f092d231d3c401a05c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2148ff9d584842f3807976a73a159b50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22a9300f49154e85a108bd20189c762e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3b6328ef1db4d35a2d3f7de26f0589d",
      "placeholder": "​",
      "style": "IPY_MODEL_d2f5e22a795841da91cabff6bca7a917",
      "value": " 347/347 [00:04&lt;00:00, 81.27 examples/s]"
     }
    },
    "3329880c492e4eb296583d04d16d172d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39cdcc8b5c4840638caf6466facf18a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbc917d8bb3e4a069233459866839d15",
      "max": 331,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3329880c492e4eb296583d04d16d172d",
      "value": 331
     }
    },
    "61153b8463664ea6a02ce511686e4a49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70dba985c09641f39b1f11d57b80d14c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83c909f6ea724db88047595ab1b1a063": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61153b8463664ea6a02ce511686e4a49",
      "placeholder": "​",
      "style": "IPY_MODEL_70dba985c09641f39b1f11d57b80d14c",
      "value": "Filter: 100%"
     }
    },
    "a05005cba0134e71ab3c27b49fbe8e56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c21588bf78fe42fea3beb97761453758",
       "IPY_MODEL_39cdcc8b5c4840638caf6466facf18a0",
       "IPY_MODEL_d580db0223ce49029c23408312074235"
      ],
      "layout": "IPY_MODEL_fd6e2798ba53421b857f41eab4174ede"
     }
    },
    "a1d0b1eb684c47d2bf9b5690bac4c706": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3b6328ef1db4d35a2d3f7de26f0589d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6c5371006294c6d88b76b58ede3545a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae415eb1770448318497619b2f598b2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd825e2bf0504c06885ae3e060a9b69b",
      "max": 347,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b20c054570047e58b56b8ba803111f2",
      "value": 347
     }
    },
    "bb994987aa01437f961e2300804efd22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c21588bf78fe42fea3beb97761453758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2148ff9d584842f3807976a73a159b50",
      "placeholder": "​",
      "style": "IPY_MODEL_bb994987aa01437f961e2300804efd22",
      "value": "Tokenizing train dataset: 100%"
     }
    },
    "cd825e2bf0504c06885ae3e060a9b69b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d04f1e30b5674a66896fd4d7345d814b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83c909f6ea724db88047595ab1b1a063",
       "IPY_MODEL_ae415eb1770448318497619b2f598b2a",
       "IPY_MODEL_22a9300f49154e85a108bd20189c762e"
      ],
      "layout": "IPY_MODEL_1ac03c5bc42847f092d231d3c401a05c"
     }
    },
    "d2f5e22a795841da91cabff6bca7a917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d580db0223ce49029c23408312074235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1d0b1eb684c47d2bf9b5690bac4c706",
      "placeholder": "​",
      "style": "IPY_MODEL_a6c5371006294c6d88b76b58ede3545a",
      "value": " 331/331 [00:08&lt;00:00, 39.89 examples/s]"
     }
    },
    "fbc917d8bb3e4a069233459866839d15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd6e2798ba53421b857f41eab4174ede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
